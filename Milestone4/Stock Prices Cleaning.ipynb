{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "043cadf4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "         date    open    high       low   close    volume stock\n",
      "0  2023-07-20  195.09  196.47  192.4950  193.13  59581196  AAPL\n",
      "1  2023-07-21  194.10  194.97  191.2300  191.94  71951683  AAPL\n",
      "2  2023-07-24  193.41  194.91  192.2500  192.75  45505097  AAPL\n",
      "3  2023-07-25  193.33  194.44  192.9150  193.62  37283201  AAPL\n",
      "4  2023-07-26  193.67  195.64  193.3200  194.50  47471868  AAPL\n",
      "..        ...     ...     ...       ...     ...       ...   ...\n",
      "95 2023-12-04  189.98  190.05  187.4511  189.43  43389519  AAPL\n",
      "96 2023-12-05  190.21  194.40  190.1800  193.42  66628398  AAPL\n",
      "97 2023-12-06  194.45  194.76  192.1100  192.32  40895115  AAPL\n",
      "98 2023-12-07  193.63  195.00  193.5900  194.27  47477655  AAPL\n",
      "99 2023-12-08  194.20  195.99  193.6700  195.71  53406358  AAPL\n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPX\n",
      "'Time Series (Daily)'\n",
      "V\n",
      "         date     open     high     low   close   volume stock\n",
      "0  2023-07-20  241.160  241.610  239.07  239.62  4694950     V\n",
      "1  2023-07-21  239.740  240.345  238.73  239.25  5427353     V\n",
      "2  2023-07-24  239.680  241.275  238.19  240.74  6009950     V\n",
      "3  2023-07-25  240.020  240.800  238.56  238.69  4997534     V\n",
      "4  2023-07-26  231.415  238.850  227.68  237.10  7551396     V\n",
      "..        ...      ...      ...     ...     ...      ...   ...\n",
      "95 2023-12-04  255.910  257.385  254.35  254.44  5247450     V\n",
      "96 2023-12-05  254.190  254.820  252.14  254.61  4199094     V\n",
      "97 2023-12-06  255.800  256.830  253.53  254.29  3804631     V\n",
      "98 2023-12-07  254.890  256.140  253.50  255.82  3589256     V\n",
      "99 2023-12-08  255.000  256.040  253.87  255.74  3732515     V\n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage, bigquery\n",
    "import pandas as pd\n",
    "from google.oauth2 import service_account\n",
    "import json\n",
    "\n",
    "# Set up Google Cloud credentials\n",
    "project_credentials = service_account.Credentials.from_service_account_file('data-finance-final-92d8049c252f.json')\n",
    "project_id = 'data-finance-final'\n",
    "\n",
    "# Initialize the client\n",
    "storage_client = storage.Client(credentials=project_credentials, project=project_id)\n",
    "bucket_name = 'data_finance_final'\n",
    "\n",
    "# Get the bucket\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "# List all blobs in the bucket\n",
    "blobs = list(bucket.list_blobs())\n",
    "\n",
    "# Process the blob names to find the most recent file for each stock\n",
    "latest_files = {}\n",
    "for blob in blobs:\n",
    "    # Assuming file names are in 'Price_STOCK-DATE.json' format\n",
    "    parts = blob.name.split('_')\n",
    "    #print(parts)\n",
    "    if len(parts) > 1 and parts[0] == 'price/Price':\n",
    "        # Extract the stock symbol and date\n",
    "        stock, date_str = parts[1], parts[2].split('.')[0]\n",
    "        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "        \n",
    "        # Determine if this file is the most recent for the stock\n",
    "        if stock not in latest_files or date > latest_files[stock]['date']:\n",
    "            latest_files[stock] = {'date': date, 'blob': blob}\n",
    "\n",
    "# Initialize BigQuery client\n",
    "bigquery_client = bigquery.Client(credentials=project_credentials, project=project_id)\n",
    "dataset_id = 'stockMetaData'\n",
    "table_id = 'stock_prices_cleaned'\n",
    "\n",
    "# Define the schema of your BigQuery table\n",
    "schema = [\n",
    "    bigquery.SchemaField('date', 'DATE'),\n",
    "    bigquery.SchemaField('open', 'FLOAT'),\n",
    "    bigquery.SchemaField('high', 'FLOAT'),\n",
    "    bigquery.SchemaField('low', 'FLOAT'),\n",
    "    bigquery.SchemaField('close', 'FLOAT'),\n",
    "    bigquery.SchemaField('volume', 'INTEGER'),\n",
    "    bigquery.SchemaField('stock', 'String')\n",
    "\n",
    "]\n",
    "\n",
    "# Create or get the dataset and table\n",
    "dataset_ref = bigquery_client.dataset(dataset_id)\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "bigquery_client.create_dataset(dataset, exists_ok=True)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "bigquery_client.create_table(table, exists_ok=True)\n",
    "\n",
    "# For each stock, load the most recent data into BigQuery\n",
    "for stock, file_info in latest_files.items():\n",
    "    print(stock)\n",
    "    \n",
    "    try:\n",
    "        # Download the blob to a local variable\n",
    "        data_string = file_info['blob'].download_as_string()\n",
    "        data_json = json.loads(data_string)\n",
    "\n",
    "        # Process and clean the data as needed, then convert to DataFrame\n",
    "        # This is an example, you'll need to adjust it to match your JSON structure\n",
    "        df = pd.DataFrame.from_dict(data_json['Time Series (Daily)'], orient='index')\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df.sort_index(inplace=True)\n",
    "\n",
    "        # Reset the index and rename columns\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'date'}, inplace=True)\n",
    "        df.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "        df['stock'] = stock\n",
    "\n",
    "        df['open'] = pd.to_numeric(df['open'], errors='coerce')\n",
    "        df['high'] = pd.to_numeric(df['high'], errors='coerce')\n",
    "        df['low'] = pd.to_numeric(df['low'], errors='coerce')\n",
    "        df['close'] = pd.to_numeric(df['close'], errors='coerce')\n",
    "        df['volume'] = pd.to_numeric(df['volume'], downcast='integer', errors='coerce')\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        print(df)\n",
    "        # If the table doesn't exist, create it, otherwise append the data\n",
    "        df.to_gbq(destination_table=f'{dataset_id}.{table_id}', project_id=project_id, if_exists='append', credentials=project_credentials)\n",
    "    except KeyError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ffc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
