{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46f5d49b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "AMZN\n",
      "FB\n",
      "Unable to Format\n",
      "GOOG\n",
      "IBM\n",
      "INTC\n",
      "MSFT\n",
      "SPX\n",
      "Unable to Format\n",
      "TSLA\n",
      "V\n",
      "        date stock  sentiment\n",
      "0 2023-12-14  AAPL   0.136018\n",
      "0 2023-12-14  AMZN   0.159763\n",
      "0 2023-12-14  GOOG   0.105519\n",
      "0 2023-12-14   IBM   0.079879\n",
      "0 2023-12-14  INTC   0.179523\n",
      "0 2023-12-14  MSFT   0.109018\n",
      "0 2023-12-14  TSLA   0.088962\n",
      "0 2023-12-14     V   0.182790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 975.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage, bigquery\n",
    "import pandas as pd\n",
    "from google.oauth2 import service_account\n",
    "import json\n",
    "\n",
    "# Set up Google Cloud credentials\n",
    "project_credentials = service_account.Credentials.from_service_account_file('data-finance-final-92d8049c252f.json')\n",
    "project_id = 'data-finance-final'\n",
    "\n",
    "# Initialize the client\n",
    "storage_client = storage.Client(credentials=project_credentials, project=project_id)\n",
    "bucket_name = 'data_finance_final'\n",
    "\n",
    "# Get the bucket\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "# List all blobs in the bucket\n",
    "blobs = list(bucket.list_blobs())\n",
    "filtered_blobs = [blob for blob in blobs if blob.name.startswith('sentiment/Sentiment')]\n",
    "#print(filtered_blobs)\n",
    "\n",
    "\n",
    "latest_files = {}\n",
    "\n",
    "for blob in filtered_blobs:\n",
    "    # Assuming file names are in 'sentiment/Sentiment_STOCK_DATE.json' format\n",
    "    parts = blob.name.split('_')\n",
    "    #print(parts)\n",
    "    if len(parts) > 1 and parts[0] == 'sentiment/Sentiment':\n",
    "        # Extract the stock symbol and date\n",
    "        stock, date_str = parts[1], parts[2].split('.')[0]\n",
    "        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "        \n",
    "        # Determine if this file is the most recent for the stock\n",
    "        if stock not in latest_files or date > latest_files[stock]['date']:\n",
    "            latest_files[stock] = {'date': date, 'blob': blob}\n",
    "\n",
    "# Initialize BigQuery client\n",
    "bigquery_client = bigquery.Client(credentials=project_credentials, project=project_id)\n",
    "dataset_id = 'stockMetaData'\n",
    "table_id = 'stock_sentiments_cleaned'\n",
    "\n",
    "# Define the schema of your BigQuery table\n",
    "schema = [\n",
    "    bigquery.SchemaField('date', 'DATE'),\n",
    "    bigquery.SchemaField('stock', 'String'),\n",
    "    bigquery.SchemaField('sentiment', 'FLOAT'),\n",
    "]\n",
    "\n",
    "# Create or get the dataset and table\n",
    "dataset_ref = bigquery_client.dataset(dataset_id)\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "bigquery_client.create_dataset(dataset, exists_ok=True)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "bigquery_client.create_table(table, exists_ok=True)\n",
    "\n",
    "df_combined = pd.DataFrame()\n",
    "for stock, file_info in latest_files.items():\n",
    "    try:\n",
    "        print(stock)\n",
    "\n",
    "        # Download the blob to a local variable\n",
    "        data_string = file_info['blob'].download_as_string()\n",
    "        data_json = json.loads(data_string)\n",
    "\n",
    "        sentiment_total = 0\n",
    "        sentiment_count = 0\n",
    "\n",
    "        # Iterate through each article in the JSON data\n",
    "        for article in data_json[\"feed\"]:\n",
    "            # Iterate through each ticker sentiment in the article\n",
    "            for ticker_info in article[\"ticker_sentiment\"]:\n",
    "                ticker = ticker_info[\"ticker\"]\n",
    "                if ticker == stock:\n",
    "                    sentiment_score = float(ticker_info[\"ticker_sentiment_score\"])\n",
    "                    sentiment_total += sentiment_score\n",
    "                    sentiment_count += 1\n",
    "\n",
    "        average_sentiment = sentiment_total / sentiment_count\n",
    "\n",
    "        columns = ['date', 'stock','sentiment']\n",
    "        df = pd.DataFrame([[file_info['date'],stock,average_sentiment]], columns=columns)\n",
    "        df_combined = pd.concat([df_combined,df], axis=0)\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(\"Unable to Format\")\n",
    "    \n",
    "        \n",
    "print(df_combined)\n",
    "\n",
    "try:\n",
    "    # If the table doesn't exist, create it, otherwise append the data\n",
    "    df_combined.to_gbq(destination_table=f'{dataset_id}.{table_id}', project_id=project_id, if_exists='replace', credentials=project_credentials)\n",
    "except KeyError as e:\n",
    "    print(\"Unable to Format\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
